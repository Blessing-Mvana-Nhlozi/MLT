{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18fa4aef-f76f-4267-89b5-8cae33309f17",
   "metadata": {},
   "source": [
    "# SABER Temperature Data Processing\n",
    "\n",
    "This notebook ingests multiple SABER compressed CSV datasets (`.csv.gz`), filters the Mesosphere-Lower Thermosphere (MLT) region, \n",
    "and produces aggregated datasets (bronze-level tables) for downstream analysis.\n",
    "\n",
    "**Pipeline stages:**\n",
    "1. Load helper functions.\n",
    "2. Read and combine raw SABER datasets.\n",
    "3. Apply filters and binning (altitude, latitude, longitude).\n",
    "4. Generate temporal aggregations:\n",
    "   - 1D (monthly)\n",
    "   - 2D (monthly-altitude, with seasonal tags)\n",
    "   - 4D (monthly-alt-lat-lon grid)\n",
    "5. Save processed tables to disk.\n",
    "\n",
    "---\n",
    "**Input:**  \n",
    "- `sutherland_timeseries_<year>.csv.gz`\n",
    "\n",
    "**Output:**  \n",
    "- `bronze_saber_4d_tempoaral_agg.csv.gz`  \n",
    "- `bronze_saber_2d_tempoaral_agg.csv.gz`  \n",
    "- `bronze_saber_1d_tempoaral_agg.csv.gz`\n",
    "- `bronze_saber_altitude_agg.csv.gz`  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aab3df48-8e0e-44b7-bd17-07c77ac6d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82abce9c-c320-4766-b894-ca8c8315c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current working directory (notebook folder)\n",
    "notebook_path = Path.cwd()  # MLT/code/data_processing/\n",
    "base_path = notebook_path.parent.parent  # Go up to MLT/\n",
    "\n",
    "functions_path = notebook_path.parent / \"000_Functions.ipynb\"\n",
    "data_path = base_path / \"data\" / \"raw\"\n",
    "bronze_path = base_path / \"data\" / \"bronze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f472d194-e6ef-4a9c-a8eb-58d29e7eeb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load custom functions\n",
    "%run \"{functions_path.as_posix()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4379831-386a-4694-aca3-f14c8285a431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with: sutherland_timeseries_2002.csv.gz\n",
      "Done with: sutherland_timeseries_2003.csv.gz\n",
      "Done with: sutherland_timeseries_2004.csv.gz\n",
      "Done with: sutherland_timeseries_2005.csv.gz\n",
      "Done with: sutherland_timeseries_2006.csv.gz\n",
      "Done with: sutherland_timeseries_2007.csv.gz\n",
      "Done with: sutherland_timeseries_2008.csv.gz\n",
      "Done with: sutherland_timeseries_2009.csv.gz\n",
      "Done with: sutherland_timeseries_2010.csv.gz\n",
      "Done with: sutherland_timeseries_2011.csv.gz\n",
      "Done with: sutherland_timeseries_2012.csv.gz\n",
      "Done with: sutherland_timeseries_2013.csv.gz\n",
      "Done with: sutherland_timeseries_2014.csv.gz\n",
      "Done with: sutherland_timeseries_2015.csv.gz\n",
      "Done with: sutherland_timeseries_2016.csv.gz\n",
      "Done with: sutherland_timeseries_2017.csv.gz\n",
      "Done with: sutherland_timeseries_2018.csv.gz\n",
      "Done with: sutherland_timeseries_2019.csv.gz\n",
      "Done with: sutherland_timeseries_2020.csv.gz\n",
      "Done with: sutherland_timeseries_2021.csv.gz\n",
      "Done with: sutherland_timeseries_2022.csv.gz\n",
      "Done with: sutherland_timeseries_2023.csv.gz\n",
      "Done with: sutherland_timeseries_2024.csv.gz\n",
      "Done with: sutherland_timeseries_2025.csv.gz\n"
     ]
    }
   ],
   "source": [
    "# years from 2002 to 2025 (inclusive)\n",
    "years = range(2002, 2026)\n",
    "\n",
    "# Read all files into a dictionary of DataFrames\n",
    "dfs = {}\n",
    "for year in years:\n",
    "    try:\n",
    "        file =   base_path / f\"data/raw/sutherland_timeseries_{year}.csv.gz\"  # adjust extension if needed\n",
    "        dfs[year] = pd.read_csv(file)\n",
    "        print(f\"Done with: sutherland_timeseries_{year}.csv.gz\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading sutherland_timeseries_{year}.csv.gz: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "602347dd-1cf2-4ae3-b0e3-50447af6e384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b39a4d-0753-48cd-bae6-cbf11246a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for MLT region (50 km to 110 km)\n",
    "df = df[(df['tpaltitude'] >= 50) & (df['tpaltitude'] <= 110)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0fec3ee-83f1-408c-b2b9-427820cdd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop null dates\n",
    "df = df[df['date'].notnull()]\n",
    "# Convert date into datetime type\n",
    "df['date'] = pd.to_datetime(\n",
    "    df['date'],\n",
    "    errors='coerce'  # <-- just in case\n",
    ")\n",
    "\n",
    "# Create 'year_month' for plotting\n",
    "df['year_month'] = df['date'].dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3045ce9-5d88-460d-ae7e-297ea20b19bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Spatial binning complete.\n"
     ]
    }
   ],
   "source": [
    "# Create 1 km bins\n",
    "bins = np.arange(50, 132, 1)\n",
    "labels = bins[:-1]\n",
    "df['altitude_bin'] = pd.cut(df['tpaltitude'], bins=bins, labels=labels, right=False)\n",
    "df = df.dropna(subset=['altitude_bin'])\n",
    "df['altitude_bin'] = df['altitude_bin'].astype(int)\n",
    "\n",
    "# Create 1 degree bins\n",
    "bins = np.arange(-37, -28, 1)\n",
    "labels = bins[:-1]\n",
    "df['latitude_bin'] = pd.cut(df['tplatitude'], bins=bins, labels=labels, right=False)\n",
    "df = df.dropna(subset=['latitude_bin'])\n",
    "df['latitude_bin'] = df['latitude_bin'].astype(int)\n",
    "\n",
    "# Create 1 degree bins\n",
    "bins = np.arange(15, 26, 1)\n",
    "labels = bins[:-1]\n",
    "df['longitude_bin'] = pd.cut(df['tplongitude'], bins=bins, labels=labels, right=False)\n",
    "df = df.dropna(subset=['longitude_bin'])\n",
    "df['longitude_bin'] = df['longitude_bin'].astype(int)\n",
    "\n",
    "print(\"[INFO] Spatial binning complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896c538f-9291-4412-97dd-c373bfcc0069",
   "metadata": {},
   "source": [
    "## Creating Bronze Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8391a572-db07-4d44-8fde-78e213c6075e",
   "metadata": {},
   "source": [
    "### bronze_saber_altitude_agg\n",
    "\n",
    "**Output:** Altitude average temperature (`ktemp`). Vertical temperature profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f5f0d2-f2db-42b0-96e7-223312df64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df_alt = df.groupby(['altitude_bin']).agg({\n",
    "    'ktemp': 'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83712239-a179-4d08-8c49-623cc78e8320",
   "metadata": {},
   "source": [
    "### bronze_saber_1d_tempoaral_agg\n",
    "\n",
    "**Output:** Monthly average `ktemp` values (time series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9362231b-1844-4ccf-86b0-87f8af86e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df_1d = df.groupby(['year_month']).agg({\n",
    "    'ktemp': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create a 'year' and 'month' column from date\n",
    "agg_df_1d['year'] = agg_df_1d['year_month'].dt.year\n",
    "agg_df_1d['month'] = agg_df_1d['year_month'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ce225-5127-48db-9887-bd5eb3e5ac99",
   "metadata": {},
   "source": [
    "### bronze_saber_2d_temporal_agg\n",
    "**Output:** Monthly Ã— altitude aggregation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a771322b-f8a4-4429-a27d-0cfa89003029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group and aggregate\n",
    "agg_df_2d = df.groupby(['year_month', 'altitude_bin']).agg({\n",
    "    'ktemp': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create a 'year' and 'month' column from date\n",
    "agg_df_2d['year'] = agg_df_2d['year_month'].dt.year\n",
    "agg_df_2d['month'] = agg_df_2d['year_month'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e4a4e-4f0e-49fe-89f8-599c24bc799c",
   "metadata": {},
   "source": [
    "### bronze_saber_4d_tempoaral_agg\n",
    "\n",
    "**Output:** 4D grid (`year_month`, `altitude_bin`, `latitude_bin`, `longitude_bin`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43c9b39d-2132-4810-ad41-b2d591602e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df_4d = df.groupby(['year_month', 'altitude_bin', 'latitude_bin', 'longitude_bin']).agg({\n",
    "    'ktemp': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create a 'year' and 'month' column from date\n",
    "agg_df_4d['year'] = agg_df_4d['year_month'].dt.year\n",
    "agg_df_4d['month'] = agg_df_4d['year_month'].dt.month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bb9fb-1975-4124-bf46-923c157366cb",
   "metadata": {},
   "source": [
    "## Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60a643ed-c267-4e0a-afa1-b95f775756e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] bronze_saber_4d_tempoaral_agg.csv.gz\n",
      "[SUCCESS] bronze_saber_2d_tempoaral_agg.csv.gz\n",
      "[SUCCESS] bronze_saber_1d_tempoaral_agg.csv.gz\n",
      "[SUCCESS] bronze_saber_altitude_agg.csv.gz\n",
      "All CSVs saved successfully\n"
     ]
    }
   ],
   "source": [
    "# Ensure silver folder exists\n",
    "bronze_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define tables to save\n",
    "tables = {'bronze_saber_4d_tempoaral_agg':agg_df_4d, \n",
    "          'bronze_saber_2d_tempoaral_agg':agg_df_2d, \n",
    "          'bronze_saber_1d_tempoaral_agg':agg_df_1d, \n",
    "          'bronze_saber_altitude_agg':agg_df_alt}\n",
    "\n",
    "for table_name, table in tables.items():\n",
    "    try:\n",
    "        file_path = bronze_path / f\"{table_name}.csv.gz\"\n",
    "        table.to_csv(file_path, index=False, compression='gzip')\n",
    "        print(f\"[SUCCESS] {table_name}.csv.gz\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Could not save {table_name}. Reason: {e}\")\n",
    "\n",
    "print(\"All CSVs saved successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
