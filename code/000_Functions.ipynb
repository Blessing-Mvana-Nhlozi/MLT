{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b4e5056-bc98-4b5f-896f-10c1220f7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numeric season and adjust year\n",
    "def get_season_info(row):\n",
    "    month = row['month']\n",
    "    year = row['year']\n",
    "    \n",
    "    if month in [12, 1, 2]:\n",
    "        num_season = 4  # Summer\n",
    "        if month == 12:\n",
    "            year_season = int(f\"{year}4\")\n",
    "        else:  # Jan, Feb → belongs to previous Dec\n",
    "            year_season = int(f\"{year-1}4\")\n",
    "    elif month in [3, 4, 5]:\n",
    "        num_season = 1  # Autumn\n",
    "        year_season = int(f\"{year}1\")\n",
    "    elif month in [6, 7, 8]:\n",
    "        num_season = 2  # Winter\n",
    "        year_season = int(f\"{year}2\")\n",
    "    else:  # [9, 10, 11]\n",
    "        num_season = 3  # Spring\n",
    "        year_season = int(f\"{year}3\")\n",
    "        \n",
    "    return pd.Series({'num_season': num_season, 'year_season': year_season})\n",
    "\n",
    "# Define seasons for Southern Hemisphere\n",
    "def month_to_season(month):\n",
    "    if month in [9, 10, 11]:\n",
    "        return 'Spring'\n",
    "    elif month in [12, 1, 2]:\n",
    "        return 'Summer'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Autumn'\n",
    "    else:\n",
    "        return 'Winter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "047ae3af-bc81-4fd5-83bd-59384a36efd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_profiles(df):\n",
    "    \"\"\"\n",
    "    Generate various temperature profiles from the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "\n",
    "    Returns:\n",
    "    - DataFrames:\n",
    "      year_profile  : DataFrame (altitude_bin-year avg),\n",
    "      year_season_profile : DataFrame (grouped by year_season),\n",
    "      season_profile: DataFrame (grouped by season),\n",
    "      mean_profile: DataFrame (altitude_bin mean values)\n",
    "    \"\"\"\n",
    "\n",
    "    # Group by altitude_bin and year_season\n",
    "    year_profile = df.groupby(['altitude_bin', 'year'])['ktemp'].mean().reset_index()\n",
    "\n",
    "    # Group by altitude_bin and year_season\n",
    "    year_season_profile = df.groupby(['altitude_bin', 'year_season'])['ktemp'].mean().reset_index()\n",
    "\n",
    "    # Group by season\n",
    "    season_profile = df.groupby(['altitude_bin', 'season'])['ktemp'].mean().reset_index()\n",
    "\n",
    "    # Mean profile across all time\n",
    "    mean_profile = df.groupby('altitude_bin')[['ktemp']].mean().reset_index()\n",
    "\n",
    "    return year_profile, year_season_profile,season_profile, mean_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e13655-834b-4bc8-9f68-f0d85fe691d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen_slope(df):\n",
    "    \"\"\"\n",
    "    Calculate Sen's slope and intercept for a given time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Must contain columns ['year_month', 'ktemp'].\n",
    "        - 'year_month' can be datetime or period type.\n",
    "        - 'ktemp' is the temperature variable.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        With columns ['sen_slope', 'intercept'].\n",
    "    \"\"\"\n",
    "    # Convert year_month to fractional year (YYYY + fraction of month)\n",
    "    x = df['year_month'].dt.to_timestamp().map(lambda d: d.year + (d.month - 1) / 12.0).values\n",
    "    y = df['ktemp'].values\n",
    "\n",
    "    slope, intercept, _, _ = theilslopes(y, x)\n",
    "\n",
    "    return pd.DataFrame([{'sen_slope': slope, 'intercept': intercept}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c0132b9-bec7-4ffb-8df4-3d4c80b70fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sen_slope_by_altitude(df):\n",
    "    \"\"\"\n",
    "    Computes Sen's slope of temperature vs. time for each altitude_bin.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['altitude_bin', 'year_month', 'ktemp']\n",
    "              'year_month' must be a pandas datetime (e.g., Period or Timestamp)\n",
    "    - compute_sen_slope: Function that computes Sen's slope given (x, y)\n",
    "\n",
    "    Returns:\n",
    "    - slopes_df: DataFrame with columns ['altitude_bin', 'sen_slope']\n",
    "    \"\"\"\n",
    "    slopes = []\n",
    "    altitudes = sorted(df['altitude_bin'].unique())\n",
    "\n",
    "    for alt in altitudes:\n",
    "        df_alt = df[df['altitude_bin'] == alt].dropna(subset=['ktemp'])\n",
    "        \n",
    "        # Convert 'year_month' to fractional year: 2001-03 -> 2001.1667\n",
    "        x = df_alt['year_month'].dt.to_timestamp().map(lambda d: d.year + (d.month - 1) / 12.0).values\n",
    "        y = df_alt['ktemp'].values\n",
    "\n",
    "        if len(x) > 1:  # Ensure enough points to compute slope\n",
    "            # from scipy.stats import theilslopes\n",
    "            slope, intercept, _, _ = theilslopes(y, x)\n",
    "        else:\n",
    "            slope = np.nan  # Not enough data to compute slope\n",
    "\n",
    "        slopes.append({'altitude_bin': alt, 'sen_slope': slope, 'intercept': intercept})\n",
    "\n",
    "    return pd.DataFrame(slopes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9fdc09b-32e4-459d-80bb-3b53278dbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mk_tests(df, mk):\n",
    "    \"\"\"\n",
    "    Runs the Mann-Kendall test for each altitude/time series and returns results as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with columns ['year_month', 'ktemp']\n",
    "    - mk: A module or object with the method original_test(series)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with columns:\n",
    "        ['trend', 'h', 'p', 'z', 'tau', 's', 'var_s', 'slope', 'intercept', 'n']\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    # Group by 'year_month' to get average per month\n",
    "    ts = df.sort_values('year_month').groupby('year_month')['ktemp'].mean().sort_index()\n",
    "\n",
    "    # Convert PeriodIndex to datetime if needed\n",
    "    if hasattr(ts.index, 'to_timestamp'):\n",
    "        ts.index = ts.index.to_timestamp()\n",
    "\n",
    "    # Drop NA values\n",
    "    ts = ts.dropna()\n",
    "\n",
    "    # Apply Mann-Kendall Test + Sen's Slope if enough data points\n",
    "    if len(ts) > 10:  # Require minimum data points\n",
    "        mk_result = mk.original_test(ts.values)\n",
    "        results.append({\n",
    "            'trend': mk_result.trend,\n",
    "            'h': getattr(mk_result, 'h', None),  # some implementations return h\n",
    "            'p': mk_result.p,\n",
    "            'z': mk_result.z,\n",
    "            'tau': mk_result.Tau,\n",
    "            's': mk_result.s,\n",
    "            'var_s': mk_result.var_s,\n",
    "            'slope': mk_result.slope,\n",
    "            'intercept': mk_result.intercept,\n",
    "            'n': len(ts)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce128369-9ead-4e6d-a525-bb88ca16d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mk_tests_by_altitude(df, mk):\n",
    "    \"\"\"\n",
    "    Runs the Mann-Kendall test for each specified altitude and returns the results as a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - agg_df: DataFrame with columns ['altitude_bin', 'year_month', 'ktemp']\n",
    "    - altitudes_to_plot: List of altitudes to test (e.g., [300, 350, 400])\n",
    "    - mk: A module or object with the method original_test(series)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with columns:\n",
    "        ['altitude_bin', 'trend', 'h', 'p', 'z', 'Tau', 's', 'var_s', 'slope', 'intercept', 'n']\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for alt in sorted(df['altitude_bin'].unique()):\n",
    "        df_alt = df[df['altitude_bin'] == alt].sort_values('year_month')\n",
    "    \n",
    "        # Group by 'year_month' to get average per month\n",
    "        ts = df_alt.groupby('year_month')['ktemp'].mean().sort_index()\n",
    "        \n",
    "        # Convert PeriodIndex to datetime for compatibility\n",
    "        ts.index = ts.index.to_timestamp()\n",
    "        \n",
    "        # Drop NA\n",
    "        ts = ts.dropna()\n",
    "    \n",
    "        # Apply Mann-Kendall Test + Sen's Slope\n",
    "        if len(ts) > 10:  # Require minimum data points\n",
    "            mk_result = mk.original_test(ts.values)\n",
    "            results.append({\n",
    "                'altitude_bin': alt,\n",
    "                'slope': mk_result.slope,\n",
    "                'trend': mk_result.trend,\n",
    "                'p': mk_result.p,\n",
    "                'z': mk_result.z,\n",
    "                'tau': mk_result.Tau,\n",
    "                's': mk_result.s,\n",
    "                'var_s': mk_result.var_s,\n",
    "                'slope': mk_result.slope,\n",
    "                'intercept': mk_result.intercept,\n",
    "                'n': len(ts)\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24a4dc9c-7c2e-43c4-bd1d-07518511edb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequential_mk_test(X, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Performs the Sequential Mann–Kendall (S-MK) test.\n",
    "    \n",
    "    Parameters:\n",
    "    - x: 1D array or list of values (time series)\n",
    "    - alpha: significance level (e.g., 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - dict containing UF, UB, crossing points, and critical value\n",
    "    \"\"\"\n",
    "    x = np.array(X)\n",
    "    n = len(x)\n",
    "    UF = np.zeros(n)\n",
    "    UB = np.zeros(n)\n",
    "\n",
    "    # Forward series (UF)\n",
    "    S = 0\n",
    "    var_s = np.zeros(n)\n",
    "    for k in range(1, n):\n",
    "        s = 0\n",
    "        for j in range(k):\n",
    "            if x[k] > x[j]:\n",
    "                s += 1\n",
    "            elif x[k] < x[j]:\n",
    "                s -= 1\n",
    "        S += s\n",
    "        var_s[k] = (k * (k + 1) * (2 * k + 5)) / 18\n",
    "        UF[k] = S / np.sqrt(var_s[k]) if var_s[k] > 0 else 0\n",
    "\n",
    "    # Backward series (UB)\n",
    "    x_reversed = x[::-1]\n",
    "    S = 0\n",
    "    for k in range(1, n):\n",
    "        s = 0\n",
    "        for j in range(k):\n",
    "            if x_reversed[k] > x_reversed[j]:\n",
    "                s += 1\n",
    "            elif x_reversed[k] < x_reversed[j]:\n",
    "                s -= 1\n",
    "        S += s\n",
    "        UB[k] = -S / np.sqrt(var_s[k]) if var_s[k] > 0 else 0\n",
    "\n",
    "    UB = UB[::-1]  # Flip UB to match forward time\n",
    "\n",
    "    # Critical Z value\n",
    "    z_crit = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    # Detect crossing points\n",
    "    cross_indices = np.where((UF - UB) > z_crit)[0]\n",
    "\n",
    "    return {\n",
    "        'UF': UF,\n",
    "        'UB': UB,\n",
    "        'z_crit': z_crit,\n",
    "        'cross_points': cross_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4805e24-f787-48ef-84f4-aed443c8b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sequential_mk_by_altitude(df, alpha=0.05):\n",
    "    results = []\n",
    "\n",
    "    for alt in sorted(df['altitude_bin'].unique()):\n",
    "        df_alt = df[df['altitude_bin'] == alt]\n",
    "        ts = df_alt.groupby('year_month')['ktemp'].mean().sort_index()\n",
    "\n",
    "        if hasattr(ts.index, 'to_timestamp'):\n",
    "            ts.index = ts.index.to_timestamp()\n",
    "\n",
    "        ts = ts.dropna()\n",
    "\n",
    "        if len(ts) > 10:\n",
    "            smk_result = sequential_mk_test(ts.values, alpha=alpha)\n",
    "            results.append({\n",
    "                'altitude_bin': alt,\n",
    "                'cross_points': smk_result['cross_points'],\n",
    "                'UF': smk_result['UF'],\n",
    "                'UB': smk_result['UB'],\n",
    "                'z_crit': smk_result['z_crit'],\n",
    "                'n': len(ts)\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e76d310e-0e96-4ab0-946e-afdd518e8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ITA_alt(df, split_ratio=0.5):\n",
    "    ita_results = []\n",
    "\n",
    "    for alt in sorted(df['altitude_bin'].unique()):\n",
    "        df_alt = df[df['altitude_bin'] == alt]\n",
    "        ts = df_alt.groupby('year_month')['ktemp'].mean().sort_index()\n",
    "\n",
    "        # Convert period to timestamp if needed\n",
    "        if hasattr(ts.index, 'to_timestamp'):\n",
    "            ts.index = ts.index.to_timestamp()\n",
    "\n",
    "        ts_values = ts.dropna().values\n",
    "        ts_values = ts_values[~np.isnan(ts_values)]  # ensure no NaNs\n",
    "        N = len(ts_values)\n",
    "\n",
    "        if N < 10:\n",
    "            continue  # skip altitudes with insufficient data\n",
    "\n",
    "        data_sorted = np.sort(ts_values)\n",
    "        split = int(N * split_ratio)\n",
    "        X = data_sorted[:split]\n",
    "        Y = data_sorted[-split:]\n",
    "\n",
    "        fit = linregress(X, Y)\n",
    "        ita_slope = fit.slope\n",
    "\n",
    "        ita_results.append({\n",
    "            'altitude_bin': alt,\n",
    "            'ita_slope': ita_slope,\n",
    "            'n': N\n",
    "        })\n",
    "\n",
    "    ita_df = pd.DataFrame(ita_results)\n",
    "\n",
    "    return ita_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab808924-ba8a-4612-9dec-5ad2e221b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ITA(df, split_ratio=0.5):\n",
    "    \"\"\"\n",
    "    Perform Innovative Trend Analysis (ITA) on a time series.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    series : pd.Series\n",
    "        Time series data with a datetime or period index.\n",
    "    split_ratio : float, default=0.5\n",
    "        Fraction of data to split into lower and upper groups (usually 0.5).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        With columns:\n",
    "        - 'ita_slope': slope of ITA regression line\n",
    "        - 'n': number of data points used\n",
    "    \"\"\"\n",
    "    ts = df.sort_index()\n",
    "\n",
    "    if hasattr(ts.index, 'to_timestamp'):\n",
    "        ts.index = ts.index.to_timestamp()\n",
    "\n",
    "    ts = ts.dropna()\n",
    "    ts_values = pd.to_numeric(ts['ktemp'], errors='coerce').values\n",
    "    ts_values = ts_values[~np.isnan(ts_values)]\n",
    "    N = len(ts_values)\n",
    "\n",
    "    if N < 10:\n",
    "        print(\"Not enough data points.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data_sorted = np.sort(ts_values)\n",
    "    split = int(N * split_ratio)\n",
    "    X = data_sorted[:split]\n",
    "    Y = data_sorted[-split:]\n",
    "\n",
    "    fit = linregress(X, Y)\n",
    "    ita_slope = fit.slope\n",
    "\n",
    "    result = pd.DataFrame([{\n",
    "        'ita_slope': ita_slope,\n",
    "        'n': N\n",
    "    }])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da812742-2ba1-457c-a862-7c3b57fe88f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trends_count(smk_results):\n",
    "    rows = []\n",
    "\n",
    "    for res in smk_results:\n",
    "        alt = res['altitude_bin']\n",
    "        UF = res['UF']\n",
    "        z_crit = res['z_crit']\n",
    "        n = res['n']\n",
    "        cross_points = res['cross_points']\n",
    "\n",
    "        # Check points exceeding significance threshold\n",
    "        significant_up = np.where(UF > z_crit)[0]\n",
    "        significant_down = np.where(UF < -z_crit)[0]\n",
    "\n",
    "        rows.append({\n",
    "            'altitude_bin': alt,\n",
    "            'increasing months': len(significant_up),\n",
    "            'decreasing months': len(significant_down),\n",
    "            'n_change_points': len(cross_points),\n",
    "            'n': n\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc1fd675-813e-4cd2-b188-575bc64eac7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sequential_mk(df, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Run the Sequential Mann-Kendall test on a temperature time series.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame with 'year_month' as period[M] and 'ktemp' as float\n",
    "    - alpha: significance level (default 0.05)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with UF, UB, and cross_point flags\n",
    "    - Dictionary with additional info: z_crit, cross_points, n\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.sort_values('year_month').reset_index(drop=True)\n",
    "    ts = df['ktemp'].values\n",
    "    n = len(ts)\n",
    "\n",
    "    UF = [0] * n\n",
    "    var_s = [0] * n\n",
    "\n",
    "    for i in range(1, n):\n",
    "        S = 0\n",
    "        for j in range(i):\n",
    "            if ts[i] > ts[j]:\n",
    "                S += 1\n",
    "            elif ts[i] < ts[j]:\n",
    "                S -= 1\n",
    "        var_s[i] = i * (i + 1) * (2 * i + 5) / 18\n",
    "        UF[i] = S / np.sqrt(var_s[i]) if var_s[i] > 0 else 0\n",
    "\n",
    "    UB = [0] * n\n",
    "    ts_rev = ts[::-1]\n",
    "    for i in range(1, n):\n",
    "        S = 0\n",
    "        for j in range(i):\n",
    "            if ts_rev[i] > ts_rev[j]:\n",
    "                S += 1\n",
    "            elif ts_rev[i] < ts_rev[j]:\n",
    "                S -= 1\n",
    "        UB[i] = -S / np.sqrt(var_s[i]) if var_s[i] > 0 else 0\n",
    "    UB = UB[::-1]\n",
    "\n",
    "    z_crit = norm.ppf(1 - alpha / 2)\n",
    "\n",
    "    cross_points = [i for i in range(n) if abs(UF[i] - UB[i]) < 1e-6]\n",
    "    cross_point_flags = [i in cross_points for i in range(n)]\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "        'year_month': df['year_month'].astype(str),\n",
    "        'UF': UF,\n",
    "        'UB': UB,\n",
    "        'cross_point': cross_point_flags\n",
    "    })\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a7d224-d10f-4f3b-a0dd-7702071b6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def seasonal_physics_loss(y_pred, short_period=10, long_period=132):\n",
    "#     \"\"\"\n",
    "#     Penalizes deviation from known sine-based seasonal structure.\n",
    "\n",
    "#     Parameters:\n",
    "#     y_pred (np.ndarray): Predicted values\n",
    "#     t (np.ndarray): Time axis (same shape as y_pred)\n",
    "#     short_period (int): Short seasonality period (e.g., 10 months)\n",
    "#     long_period (int): Long seasonality period (e.g., 132 months)\n",
    "\n",
    "#     Returns:\n",
    "#     float: Mean squared residual from expected harmonic structure\n",
    "#     \"\"\"\n",
    "#     t = np.arange(len(y_pred))\n",
    "    \n",
    "#     short_season = np.sin(2 * np.pi * t / short_period)\n",
    "#     long_season = np.sin(2 * np.pi * (t + 20) / long_period)\n",
    "    \n",
    "#     # Simple least-squares fit\n",
    "#     X = np.vstack([short_season, long_season, t, np.ones_like(t)]).T\n",
    "#     coeffs, _, _, _ = np.linalg.lstsq(X, y_pred, rcond=None)\n",
    "#     y_fit = X @ coeffs\n",
    "\n",
    "#     # Residual between predicted and harmonic model\n",
    "#     residual = y_pred - y_fit\n",
    "#     return np.mean(residual ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "242474af-65ab-4c3f-aece-c9e2b28f75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Squared Error loss.\n",
    "    \n",
    "    Parameters:\n",
    "    y_true (np.ndarray): Ground truth values\n",
    "    y_pred (np.ndarray): Predicted values\n",
    "    \n",
    "    Returns:\n",
    "    float: Mean Squared Error\n",
    "    \"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bfcdf32-ca9c-4ced-8dc0-bb74db6bcc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ODE_loss(y_pred, a=0.01):\n",
    "#     \"\"\"\n",
    "#     Physics-informed loss for: y'' + y = -a * t\n",
    "\n",
    "#     Parameters:\n",
    "#     y_pred (np.ndarray): Predicted values\n",
    "#     t (np.ndarray): Time steps\n",
    "#     a (float): Coefficient for the forcing term\n",
    "\n",
    "#     Returns:\n",
    "#     float: Physics residual loss\n",
    "#     \"\"\"\n",
    "\n",
    "#     t = np.arrange(len(y_pred))\n",
    "    \n",
    "#     # Finite difference approximation for y''\n",
    "#     dt = t[1] - t[0]\n",
    "#     y_tt = (y_pred[:-2] - 2 * y_pred[1:-1] + y_pred[2:]) / (dt ** 2)\n",
    "\n",
    "#     y_mid = y_pred[1:-1]\n",
    "#     t_mid = t[1:-1]\n",
    "#     # Compute residual of the differential equation: y'' + y + a*t = 0\n",
    "#     residual = y_tt + y_mid + a * t_mid\n",
    "#     # Mean squared residual\n",
    "#     return np.mean(residual ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc258092-94da-47dd-859c-fee182ff6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ODE_loss_fn(a=0.01):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Assume uniform time steps: t = 0, 1, 2, ..., N-1\n",
    "        t = tf.range(tf.shape(y_pred)[1], dtype=tf.float32)\n",
    "        dt = t[1] - t[0]\n",
    "\n",
    "        # Slicing for finite difference (along sequence dimension)\n",
    "        y_left = y_pred[:, :-2]\n",
    "        y_mid = y_pred[:, 1:-1]\n",
    "        y_right = y_pred[:, 2:]\n",
    "        t_mid = t[1:-1]\n",
    "\n",
    "        # Finite difference second derivative\n",
    "        y_tt = (y_left - 2 * y_mid + y_right) / (dt ** 2)\n",
    "\n",
    "        # Residual of the ODE: y'' + y + a*t = 0\n",
    "        residual = y_tt + y_mid + a * t_mid  # broadcasting happens automatically\n",
    "        return tf.reduce_mean(tf.square(residual))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a24c8806-5e6b-4c8a-a378-84e0ac90b922",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seasonal_physics_loss_tf(short_period=10, long_period=132):\n",
    "    def loss(y_true, y_pred):\n",
    "        # Assume shape: (batch_size, time_steps)\n",
    "        time_steps = tf.shape(y_pred)[1]\n",
    "        t = tf.cast(tf.range(time_steps), tf.float32)  # shape: (time_steps,)\n",
    "\n",
    "        # Build harmonic basis\n",
    "        short_season = tf.sin(2 * np.pi * t / short_period)\n",
    "        long_season = tf.sin(2 * np.pi * (t + 20) / long_period)\n",
    "\n",
    "        # Design matrix: (time_steps, 4)\n",
    "        X = tf.stack([short_season, long_season, t, tf.ones_like(t)], axis=1)  # shape: (T, 4)\n",
    "\n",
    "        # Least squares fit for each sample in batch\n",
    "        def single_residual(y_i):\n",
    "            # y_i shape: (time_steps,)\n",
    "            coeffs = tf.linalg.lstsq(X, tf.reshape(y_i, [-1, 1]), l2_regularizer=0.0, fast=False)  # (4,1)\n",
    "            y_fit = tf.matmul(X, coeffs)  # (T,1)\n",
    "            residual = tf.reshape(y_i, [-1, 1]) - y_fit\n",
    "            return tf.reduce_mean(tf.square(residual))\n",
    "\n",
    "        # Apply to each sample in the batch\n",
    "        residuals = tf.map_fn(single_residual, y_pred, dtype=tf.float32)\n",
    "        return tf.reduce_mean(residuals)  # Final scalar loss\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27dff717-4291-44fd-96c7-89b31ec50585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_loss_fn(a=0.01, b=0, lambda_mse=1.0, lambda_ode=1.0):\n",
    "    def loss(y_true, y_pred):\n",
    "        # MSE loss\n",
    "        mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "        # ODE loss\n",
    "        t = tf.range(tf.shape(y_pred)[1], dtype=tf.float32)\n",
    "        dt = t[1] - t[0]\n",
    "\n",
    "        y_left = y_pred[:, :-2]\n",
    "        y_mid = y_pred[:, 1:-1]\n",
    "        y_right = y_pred[:, 2:]\n",
    "        t_mid = t[1:-1]\n",
    "\n",
    "        y_tt = (y_left - 2 * y_mid + y_right) / (dt ** 2)\n",
    "        residual = y_tt + y_mid + a * t_mid + b\n",
    "        ode = tf.reduce_mean(tf.square(residual))\n",
    "\n",
    "        # Combine losses\n",
    "        return lambda_mse * mse + lambda_ode * ode\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "295dda62-510d-4c66-a42d-3c619e299979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point-wise metrics\n",
    "def mae(y_true, y_pred):\n",
    "    return np.mean(np.abs(y_true - y_pred))\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred)**2)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mse(y_true, y_pred))\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    mask = denominator != 0\n",
    "    return np.mean(np.abs(y_true - y_pred)[mask] / denominator[mask]) * 100\n",
    "\n",
    "# MASE\n",
    "def mase(y_true, y_pred, seasonality=1):\n",
    "    naive_forecast = y_true[:-seasonality]\n",
    "    scale = np.mean(np.abs(y_true[seasonality:] - naive_forecast))\n",
    "    return np.mean(np.abs(y_true[seasonality:] - y_pred[seasonality:])) / scale\n",
    "\n",
    "# NSE\n",
    "def nse(y_true, y_pred):\n",
    "    return 1 - np.sum((y_true - y_pred)**2) / np.sum((y_true - np.mean(y_true))**2)\n",
    "\n",
    "# Forecast skill\n",
    "def skill_score(y_true, y_pred, baseline_pred):\n",
    "    model_error = mse(y_true, y_pred)\n",
    "    baseline_error = mse(y_true, baseline_pred)\n",
    "    return 1 - model_error / baseline_error\n",
    "\n",
    "# Residual autocorrelation\n",
    "def residual_acf(y_true, y_pred, nlags=20):\n",
    "    residuals = y_true - y_pred\n",
    "    return acf(residuals.flatten(), nlags=nlags)\n",
    "\n",
    "\n",
    "\n",
    "def quantile_loss(y_true, y_pred, quantile=0.9):\n",
    "    error = y_true - y_pred\n",
    "    return np.mean(np.maximum(quantile * error, (quantile - 1) * error))\n",
    "\n",
    "\n",
    "def picp(y_true, lower, upper):\n",
    "    within_interval = np.logical_and(y_true >= lower, y_true <= upper)\n",
    "    return np.mean(within_interval)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dtw_distance(y_true, y_pred):\n",
    "    return dtw.distance(y_true, y_pred)\n",
    "\n",
    "\n",
    "\n",
    "def crps_score(y_true, y_samples):\n",
    "    \"\"\"\n",
    "    y_true: shape (n_samples,)\n",
    "    y_samples: shape (n_samples, n_ensemble_members)\n",
    "    \"\"\"\n",
    "    return np.mean(crps_ensemble(y_true, y_samples))\n",
    "\n",
    "\n",
    "def pinball_loss(y_true, y_pred, quantile):\n",
    "    error = y_true - y_pred\n",
    "    return np.mean(np.maximum(quantile * error, (quantile - 1) * error))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def residual_autocorrelation(y_true, y_pred, lags=20):\n",
    "    residuals = y_true - y_pred\n",
    "    return acf(residuals, nlags=lags)\n",
    "\n",
    "\n",
    "def nash_sutcliffe_efficiency(y_true, y_pred):\n",
    "    numerator = np.sum((y_true - y_pred)**2)\n",
    "    denominator = np.sum((y_true - np.mean(y_true))**2)\n",
    "    return 1 - (numerator / denominator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9b9c4fa-04a4-444f-988d-fcd9d1bf8501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_forecast(y_true, y_pred, baseline_pred=None, title=None):\n",
    "    y_true = y_true.reshape(-1)\n",
    "    y_pred = y_pred.reshape(-1)\n",
    "\n",
    "    print(\"Forecast Evaluation Metrics:\")\n",
    "    print(f\"MAE     : {mae(y_true, y_pred):.4f}\")\n",
    "    print(f\"MSE     : {mse(y_true, y_pred):.4f}\")\n",
    "    print(f\"RMSE    : {rmse(y_true, y_pred):.4f}\")\n",
    "    print(f\"MAPE    : {mape(y_true, y_pred):.2f}%\")\n",
    "    print(f\"sMAPE   : {smape(y_true, y_pred):.2f}%\")\n",
    "    print(f\"MASE    : {mase(y_true, y_pred):.4f}\")\n",
    "    print(f\"NSE     : {nse(y_true, y_pred):.4f}\")\n",
    "    if baseline_pred is not None:\n",
    "        print(f\"Skill Score vs Baseline: {skill_score(y_true.reshape(y_true.shape[0], -1), y_pred.reshape(y_pred.shape[0], -1), baseline_pred.reshape(y_pred.shape)):.4f}\")\n",
    "\n",
    "    print(\"\\n Residual ACF (lags 1–5):\", np.round(residual_acf(y_true, y_pred, nlags=5)[1:], 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
