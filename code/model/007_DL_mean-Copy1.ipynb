{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0728753c-dade-48ea-8427-c086f68b5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "import datetime as dt\n",
    "import pymannkendall as mk\n",
    "from properscoring import crps_ensemble\n",
    "from dtaidistance import dtw\n",
    "from statsmodels.tsa.stattools import acf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7585757-7ae7-40c2-82a3-bcc619aa9605",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:\\Users\\mvana\\Documents\\MSc\\Temp_O3_H2O\\000_Functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6165751c-6a1d-4bac-bb27-8e09ef825d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into tf.data.Dataset\n",
    "dataset = tf.data.experimental.make_csv_dataset(\n",
    "    file_pattern=r\"C:\\Users\\mvana\\Documents\\MSc\\Temp_O3_H2O\\Data\\monthly_series.csv\",\n",
    "    batch_size=1, num_epochs=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1272390b-3c06-4ef9-a38f-d6c8b44b96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect into a dict of tensors\n",
    "dataset = dataset.unbatch().batch(10_000)  # adjust size\n",
    "data_dict = next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3ed7957-308d-490e-9ec5-d973ea91345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate year_month\n",
    "year_month = data_dict.pop(\"year_month\")  # shape (N,)\n",
    "timeseries = tf.stack(list(data_dict.values()), axis=1)  # (N, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "248840a6-edd5-423d-93f5-355014f1ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values (NaN -> 0 or forward-fill)\n",
    "timeseries = tf.where(tf.math.is_nan(timeseries),\n",
    "                      tf.zeros_like(timeseries),\n",
    "                      timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20305ce2-5f87-4218-9267-b6076d9fcc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numeric time index\n",
    "time_index = tf.range(tf.shape(timeseries)[0], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ae2f978-5e3c-48de-8195-a02a78c04481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MinMax scaling ---\n",
    "min_vals = tf.reduce_min(timeseries, axis=0)\n",
    "max_vals = tf.reduce_max(timeseries, axis=0)\n",
    "timeseries_scaled = (timeseries - min_vals) / (max_vals - min_vals + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da795c59-cbd8-4ad3-b2d3-d56336768858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (16, 24, 1)\n",
      "y shape: (16, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 24\n",
    "PRED_LEN = 24\n",
    "\n",
    "# Build the targets explicitly as sliding windows of length PRED_LEN\n",
    "targets = np.array([\n",
    "    timeseries_scaled[i+SEQ_LEN : i+SEQ_LEN+PRED_LEN]\n",
    "    for i in range(len(timeseries_scaled) - SEQ_LEN - PRED_LEN + 1)\n",
    "])\n",
    "\n",
    "# Now create the dataset\n",
    "dataset = tf.keras.utils.timeseries_dataset_from_array(\n",
    "    data=timeseries_scaled[:-PRED_LEN],  # input sequences\n",
    "    targets=targets,                     # multi-step targets\n",
    "    sequence_length=SEQ_LEN,\n",
    "    sequence_stride=1,\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "# Inspect one batch\n",
    "for X_batch, y_batch in dataset.take(1):\n",
    "    print(\"X shape:\", X_batch.shape)  # (batch, SEQ_LEN, features)\n",
    "    print(\"y shape:\", y_batch.shape)  # (batch, PRED_LEN, features) or (batch, PRED_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a28e9d35-5352-4ea8-aa05-3d42d0668a12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slope' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 13\u001b[0m\n\u001b[0;32m      9\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mloss_fn, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSEQ_LEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPRED_LEN\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 8\u001b[0m, in \u001b[0;36mbuild_model\u001b[1;34m(seq_len, pred_len)\u001b[0m\n\u001b[0;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m layers\u001b[38;5;241m.\u001b[39mDense(pred_len)(x)\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39minputs, outputs \u001b[38;5;241m=\u001b[39m outputs)\n\u001b[1;32m----> 8\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m combined_loss_fn(a\u001b[38;5;241m=\u001b[39m\u001b[43mslope\u001b[49m, b\u001b[38;5;241m=\u001b[39mintercept_scaled, lambda_mse\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, lambda_ode\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mloss_fn, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmse\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mNameError\u001b[0m: name 'slope' is not defined"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "def build_model(seq_len, pred_len):\n",
    "    inputs = layers.Input(shape=(seq_len, 1))\n",
    "    x = layers.LSTM(64, return_sequences=False, activation='relu')(inputs)\n",
    "    x = layers.Dense(32, activation='relu')(x)\n",
    "    outputs = layers.Dense(pred_len)(x)\n",
    "    model = models.Model(inputs=inputs, outputs = outputs)\n",
    "    loss_fn = combined_loss_fn(a=slope, b=intercept_scaled, lambda_mse=1.0, lambda_ode=0.5)\n",
    "    model.compile(optimizer='adam', loss=loss_fn, metrics=['mae', 'mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(SEQ_LEN, PRED_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63527c47-9426-4278-9f43-9b39b7960475",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(dataset, epochs=500, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95c1acf-7b80-43ed-b09a-d24d2050fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting accuracy\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(history.history['mae'], label='Train MAE')\n",
    "plt.plot(history.history['val_mae'], label='Val MAE')\n",
    "plt.title('Model MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(history.history['mse'], label='Train MSE')\n",
    "plt.plot(history.history['val_mse'], label='Val MSE')\n",
    "plt.title('Model MSE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting loss\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a4cc05-0806-49c5-8b13-9a95748a1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the last sequence from your dataset\n",
    "last_input = timeseries_scaled[-SEQ_LEN:]\n",
    "# Reshape to match model input shape\n",
    "last_input = last_input.reshape(1, SEQ_LEN, 1)\n",
    "# Predict\n",
    "forecast_scaled = model.predict(last_input)\n",
    "# Unscale forecast\n",
    "forecast_unscaled_raw = scaler.inverse_transform(forecast_scaled.reshape(-1, 1)).flatten()\n",
    "# Shift forecast: timeseries[-1] becomes forecast_unscaled[0], forecast_unscaled_raw[0] becomes [1], etc.\n",
    "forecast_unscaled = np.concatenate([timeseries.values[-1], forecast_unscaled_raw[:-1]])\n",
    "# Set parameters\n",
    "start_date = np.datetime64(\"2002-01\", 'M')\n",
    "\n",
    "date_index = np.arange(start_date, start_date + n, dtype='datetime64[M]')\n",
    "\n",
    "# Create forecast dates: PRED_LEN months after last original date\n",
    "PRED_LEN = 24  # or your actual prediction length\n",
    "forecast_start = date_index[-1]# + 1\n",
    "forecast_dates = np.arange(forecast_start, forecast_start + PRED_LEN, dtype='datetime64[M]')\n",
    "\n",
    "# Combine full time range for xticks\n",
    "full_time_range = np.concatenate([date_index, forecast_dates])\n",
    "tick_locs = np.arange(date_index[0], full_time_range[-1] + 1, 6, dtype='datetime64[M]')\n",
    "\n",
    "# Compute the trend line equation string\n",
    "slope = result.slope\n",
    "intercept = result.intercept\n",
    "equation_text = f\"Linear Trend: y ={slope:.4f}*t +  {intercept:.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b5483-d5af-4fe9-b947-02097cb94729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(15, 3), dpi=1000)\n",
    "plt.plot(date_index, timeseries, marker='o', label=\"Original\")\n",
    "plt.plot(date_index, df['sen_trend'], label=\"Sen's Slope Trend\")\n",
    "plt.plot(forecast_dates, forecast_unscaled, label=\"Forecast\", color=\"red\")\n",
    "# plt.fill_between(forecast_dates, lower_bound, upper_bound, color='red', alpha=0.2, label=\"95% CI\")\n",
    "plt.axvline(date_index[-1], color='gray', linestyle='--', linewidth=1)\n",
    "plt.xticks(tick_locs, rotation=45)\n",
    "\n",
    "# Add the equation text\n",
    "plt.text(\n",
    "    x=date_index[len(date_index) // 3],  # adjust index for placement\n",
    "    y=max(df['ktemp']) - 0.5,     # adjust y-position as needed\n",
    "    s=equation_text,\n",
    "    fontsize=12,\n",
    "    color='darkred',\n",
    "    bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray')\n",
    ")\n",
    "\n",
    "plt.legend()\n",
    "# plt.title(\"Physics-Informed LSTM Forecast\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"ktemp\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"C:\\Users\\mvana\\Documents\\MSc\\Temp_O3_H2O\\Plots\\publish\\Time_Series_Forecast.png\", format='png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d40de0-1660-42b7-b8d1-dc452d738ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X_test.reshape(-1, SEQ_LEN, 1))\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Test RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f4bbf1-2fb9-4189-ba00-ebc1044eb295",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MAE:\", mean_absolute_error(y_test, y_pred))\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE:\", root_mean_squared_error(y_test, y_pred))\n",
    "print(\"MAPE:\", mean_absolute_percentage_error(y_test, y_pred))\n",
    "print(\"sMAPE:\", symmetric_mape(y_test, y_pred))\n",
    "print(\"MASE:\", mean_absolute_scaled_error(y_test, y_pred))\n",
    "print(\"Quantile loss:\", quantile_loss(y_test, y_pred, quantile=0.9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189ac06-54d9-42de-9063-bdf34e555c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DTW:\", dtw_distance(y_test[0], y_pred[0]))\n",
    "print(\"Pinball (q=0.9):\", pinball_loss(y_test, y_pred, 0.9))\n",
    "print(\"FSS (vs. naive):\", forecast_skill_score(np.mean((y_test - y_pred)**2), 1.0))\n",
    "print(\"NSE:\", nash_sutcliffe_efficiency(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efd4276-13ed-49cf-9ce1-56879c083e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive baseline\n",
    "baseline_pred = np.tile(X_test[:, -1].reshape(-1, 1), (1, PRED_LEN))  # last observed value repeated\n",
    "\n",
    "# Evaluate\n",
    "evaluate_forecast(y_test, y_pred, baseline_pred=baseline_pred, title=\"LSTM Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa14092-4e86-405b-ae46-c34e9e8c032c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23645c9c-3245-4bc1-97a8-14aa33d2eca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
